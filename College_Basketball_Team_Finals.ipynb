{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "College Basketball Team Finals",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMukHP4jpK0QrQANWX9MN/p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ALK26/Projects/blob/master/College_Basketball_Team_Finals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXehPbPNscQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicting the Winning College Basketball Team\n",
        "# to determine which basketball teams are most likely to make it to the semifinal round of the College Basketball Tournament known as the Final Four.\n",
        "# Now equipped with the skills to use different Machine Learning algorithms, will have the opportunity to practice and apply it on a data set.  \n",
        "\n",
        "#In this scenario, you are a Data Scientist working for a college basketball team. \n",
        "# Your coaches have asked you to look at historical data to see which team metrics (individually or in combination) make a team more likely to make it into the Final Four. \n",
        "# For example, if a team is more efficient defensively, does this have a direct relationship to their ability to get into the Final Four? \n",
        "# What about defensively efficiency along with overall wins? \n",
        "# Your job is to figure out if there is a combination of metrics that give a team more of a chance of making it into this tournament.\n",
        "\n",
        "# Something to keep in mind is that when trying to predict results of basketball tournaments there are many variables that need to be taken into account. \n",
        "# As a result of this creating accurate models is incredibly hard. \n",
        "# In the sports betting industry an accuracy rate of anything over 55% is considered good as it indicates profits.\n",
        "\n",
        "# You will load a historical data set from previous seasons, clean the data, and apply different classification algorithms to the data. \n",
        "# You are expected to use the following algorithms to build your models:\n",
        "  # k-Nearest Neighbour\n",
        "  # Decision Tree\n",
        "  # Support Vector Machine\n",
        "  # Logistic Regression\n",
        "#The results are reported as the accuracy of each classifier, using the following metrics when applicable: \n",
        "  # Jaccard index\n",
        "  # F1-score\n",
        "  # Accuracy \n",
        "\n",
        "#Review Criteria\n",
        "  # Build a KNN model using a value of k equals five, find the accuracy on the validation data (1 mark )\n",
        "  # Determine the accuracy for the first 15 values of k the on the validation data:. (1 mark )\n",
        "  # Determine the minimum value for the parameter that improves results on validation data. (1 marks)\n",
        "  # Building model using Support Vector Machine. (2 marks)\n",
        "  # Train a logistic regression model and determine the accuracy of the validation data (set C=0.01) (2 marks)\n",
        "  # Calculate the F1 score and Jaccard Similarity score for each model from above. Use the Hyperparameter that performed best on the validation data (2 marks)\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqXeacILtW52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We load a dataset using Pandas library, and apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n",
        "\n",
        "# first load required libraries:\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import NullFormatter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn import preprocessing\n",
        "%matplotlib inline"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuNmsG4Otb2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#About dataset\n",
        "#This dataset is about the performance of basketball teams. The cbb.csv data set includes performance data about five seasons of 354 basketball teams. It includes following fields:\n",
        "\n",
        "#Field\tDescription\n",
        "#TEAM\tThe Division I college basketball school\n",
        "#CONF\tThe Athletic Conference in which the school participates in (A10 = Atlantic 10, ACC = Atlantic Coast Conference, AE = America East, Amer = American, ASun = ASUN, B10 = Big Ten, B12 = Big 12, BE = Big East, BSky = Big Sky, BSth = Big South, BW = Big West, CAA = Colonial Athletic Association, CUSA = Conference USA, Horz = Horizon League, Ivy = Ivy League, MAAC = Metro Atlantic Athletic Conference, MAC = Mid-American Conference, MEAC = Mid-Eastern Athletic Conference, MVC = Missouri Valley Conference, MWC = Mountain West, NEC = Northeast Conference, OVC = Ohio Valley Conference, P12 = Pac-12, Pat = Patriot League, SB = Sun Belt, SC = Southern Conference, SEC = South Eastern Conference, Slnd = Southland Conference, Sum = Summit League, SWAC = Southwestern Athletic Conference, WAC = Western Athletic Conference, WCC = West Coast Conference)\n",
        "#G\tNumber of games played\n",
        "#W\tNumber of games won\n",
        "#ADJOE\tAdjusted Offensive Efficiency (An estimate of the offensive efficiency (points scored per 100 possessions) a team would have against the average Division I defense)\n",
        "#ADJDE\tAdjusted Defensive Efficiency (An estimate of the defensive efficiency (points allowed per 100 possessions) a team would have against the average Division I offense)\n",
        "#BARTHAG\tPower Rating (Chance of beating an average Division I team)\n",
        "#EFG_O\tEffective Field Goal Percentage Shot\n",
        "#EFG_D\tEffective Field Goal Percentage Allowed\n",
        "#TOR\tTurnover Percentage Allowed (Turnover Rate)\n",
        "#TORD\tTurnover Percentage Committed (Steal Rate)\n",
        "#ORB\tOffensive Rebound Percentage\n",
        "#DRB\tDefensive Rebound Percentage\n",
        "#FTR\tFree Throw Rate (How often the given team shoots Free Throws)\n",
        "#FTRD\tFree Throw Rate Allowed\n",
        "#2P_O\tTwo-Point Shooting Percentage\n",
        "#2P_D\tTwo-Point Shooting Percentage Allowed\n",
        "#3P_O\tThree-Point Shooting Percentage\n",
        "#3P_D\tThree-Point Shooting Percentage Allowed\n",
        "#ADJ_T\tAdjusted Tempo (An estimate of the tempo (possessions per 40 minutes) a team would have against the team that wants to play at an average Division I tempo)\n",
        "#WAB\tWins Above Bubble (The bubble refers to the cut off between making the NCAA March Madness Tournament and not making it)\n",
        "#POSTSEASON\tRound where the given team was eliminated or where their season ended (R68 = First Four, R64 = Round of 64, R32 = Round of 32, S16 = Sweet Sixteen, E8 = Elite Eight, F4 = Final Four, 2ND = Runner-up, Champion = Winner of the NCAA March Madness Tournament for that given year)\n",
        "#SEED\tSeed in the NCAA March Madness Tournament\n",
        "#YEAR\tSeason\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-OL5IL4tsYX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1d3241ca-045e-4ec8-ad9d-2c2ed771285c"
      },
      "source": [
        "# Load Data From CSV File\n",
        "# load the dataset [NB Need to provide link to csv file]\n",
        "\n",
        "df = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0120ENv3/Dataset/ML0101EN_EDX_skill_up/cbb.csv')\n",
        "df.head()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEAM</th>\n",
              "      <th>CONF</th>\n",
              "      <th>G</th>\n",
              "      <th>W</th>\n",
              "      <th>ADJOE</th>\n",
              "      <th>ADJDE</th>\n",
              "      <th>BARTHAG</th>\n",
              "      <th>EFG_O</th>\n",
              "      <th>EFG_D</th>\n",
              "      <th>TOR</th>\n",
              "      <th>TORD</th>\n",
              "      <th>ORB</th>\n",
              "      <th>DRB</th>\n",
              "      <th>FTR</th>\n",
              "      <th>FTRD</th>\n",
              "      <th>2P_O</th>\n",
              "      <th>2P_D</th>\n",
              "      <th>3P_O</th>\n",
              "      <th>3P_D</th>\n",
              "      <th>ADJ_T</th>\n",
              "      <th>WAB</th>\n",
              "      <th>POSTSEASON</th>\n",
              "      <th>SEED</th>\n",
              "      <th>YEAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>North Carolina</td>\n",
              "      <td>ACC</td>\n",
              "      <td>40</td>\n",
              "      <td>33</td>\n",
              "      <td>123.3</td>\n",
              "      <td>94.9</td>\n",
              "      <td>0.9531</td>\n",
              "      <td>52.6</td>\n",
              "      <td>48.1</td>\n",
              "      <td>15.4</td>\n",
              "      <td>18.2</td>\n",
              "      <td>40.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>32.3</td>\n",
              "      <td>30.4</td>\n",
              "      <td>53.9</td>\n",
              "      <td>44.6</td>\n",
              "      <td>32.7</td>\n",
              "      <td>36.2</td>\n",
              "      <td>71.7</td>\n",
              "      <td>8.6</td>\n",
              "      <td>2ND</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Villanova</td>\n",
              "      <td>BE</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>123.1</td>\n",
              "      <td>90.9</td>\n",
              "      <td>0.9703</td>\n",
              "      <td>56.1</td>\n",
              "      <td>46.7</td>\n",
              "      <td>16.3</td>\n",
              "      <td>20.6</td>\n",
              "      <td>28.2</td>\n",
              "      <td>29.4</td>\n",
              "      <td>34.1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>57.4</td>\n",
              "      <td>44.1</td>\n",
              "      <td>36.2</td>\n",
              "      <td>33.9</td>\n",
              "      <td>66.7</td>\n",
              "      <td>8.9</td>\n",
              "      <td>Champions</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Notre Dame</td>\n",
              "      <td>ACC</td>\n",
              "      <td>36</td>\n",
              "      <td>24</td>\n",
              "      <td>118.3</td>\n",
              "      <td>103.3</td>\n",
              "      <td>0.8269</td>\n",
              "      <td>54.0</td>\n",
              "      <td>49.5</td>\n",
              "      <td>15.3</td>\n",
              "      <td>14.8</td>\n",
              "      <td>32.7</td>\n",
              "      <td>32.1</td>\n",
              "      <td>32.9</td>\n",
              "      <td>26.0</td>\n",
              "      <td>52.9</td>\n",
              "      <td>46.5</td>\n",
              "      <td>37.4</td>\n",
              "      <td>36.9</td>\n",
              "      <td>65.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>E8</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>ACC</td>\n",
              "      <td>37</td>\n",
              "      <td>29</td>\n",
              "      <td>119.9</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.9600</td>\n",
              "      <td>54.8</td>\n",
              "      <td>48.4</td>\n",
              "      <td>15.1</td>\n",
              "      <td>18.8</td>\n",
              "      <td>29.9</td>\n",
              "      <td>25.2</td>\n",
              "      <td>32.1</td>\n",
              "      <td>33.4</td>\n",
              "      <td>52.6</td>\n",
              "      <td>46.3</td>\n",
              "      <td>40.3</td>\n",
              "      <td>34.7</td>\n",
              "      <td>61.9</td>\n",
              "      <td>8.6</td>\n",
              "      <td>E8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kansas</td>\n",
              "      <td>B12</td>\n",
              "      <td>37</td>\n",
              "      <td>32</td>\n",
              "      <td>120.9</td>\n",
              "      <td>90.4</td>\n",
              "      <td>0.9662</td>\n",
              "      <td>55.7</td>\n",
              "      <td>45.1</td>\n",
              "      <td>17.8</td>\n",
              "      <td>18.5</td>\n",
              "      <td>32.2</td>\n",
              "      <td>27.9</td>\n",
              "      <td>38.6</td>\n",
              "      <td>37.3</td>\n",
              "      <td>52.7</td>\n",
              "      <td>43.4</td>\n",
              "      <td>41.3</td>\n",
              "      <td>32.5</td>\n",
              "      <td>70.1</td>\n",
              "      <td>11.6</td>\n",
              "      <td>E8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             TEAM CONF   G   W  ADJOE  ...  ADJ_T   WAB  POSTSEASON  SEED  YEAR\n",
              "0  North Carolina  ACC  40  33  123.3  ...   71.7   8.6         2ND   1.0  2016\n",
              "1       Villanova   BE  40  35  123.1  ...   66.7   8.9   Champions   2.0  2016\n",
              "2      Notre Dame  ACC  36  24  118.3  ...   65.5   2.3          E8   6.0  2016\n",
              "3        Virginia  ACC  37  29  119.9  ...   61.9   8.6          E8   1.0  2016\n",
              "4          Kansas  B12  37  32  120.9  ...   70.1  11.6          E8   1.0  2016\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWNPmkG1txo9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45ee5699-3a52-4792-e125-bfa971d242aa"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1406, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSrEHzZqtyWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add Column\n",
        "# add a column that will contain \"true\" if the wins above bubble are over 7 and \"false\" if not. call this column Win Index or \"windex\" for short.\n",
        "\n",
        "df['windex'] = np.where(df.WAB > 7, 'True', 'False')"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4CvBQJGt2KH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5606fcd4-0d65-4e42-8e81-99d42229107d"
      },
      "source": [
        "# Data visualization and pre-processing\n",
        "# filter the data set to the teams that made the Sweet Sixteen, the Elite Eight, and the Final Four in the post season. create a new dataframe that will hold the values with the new column.\n",
        "\n",
        "df1 = df.loc[df['POSTSEASON'].str.contains('F4|S16|E8', na=False)]\n",
        "df1.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEAM</th>\n",
              "      <th>CONF</th>\n",
              "      <th>G</th>\n",
              "      <th>W</th>\n",
              "      <th>ADJOE</th>\n",
              "      <th>ADJDE</th>\n",
              "      <th>BARTHAG</th>\n",
              "      <th>EFG_O</th>\n",
              "      <th>EFG_D</th>\n",
              "      <th>TOR</th>\n",
              "      <th>TORD</th>\n",
              "      <th>ORB</th>\n",
              "      <th>DRB</th>\n",
              "      <th>FTR</th>\n",
              "      <th>FTRD</th>\n",
              "      <th>2P_O</th>\n",
              "      <th>2P_D</th>\n",
              "      <th>3P_O</th>\n",
              "      <th>3P_D</th>\n",
              "      <th>ADJ_T</th>\n",
              "      <th>WAB</th>\n",
              "      <th>POSTSEASON</th>\n",
              "      <th>SEED</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>windex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Notre Dame</td>\n",
              "      <td>ACC</td>\n",
              "      <td>36</td>\n",
              "      <td>24</td>\n",
              "      <td>118.3</td>\n",
              "      <td>103.3</td>\n",
              "      <td>0.8269</td>\n",
              "      <td>54.0</td>\n",
              "      <td>49.5</td>\n",
              "      <td>15.3</td>\n",
              "      <td>14.8</td>\n",
              "      <td>32.7</td>\n",
              "      <td>32.1</td>\n",
              "      <td>32.9</td>\n",
              "      <td>26.0</td>\n",
              "      <td>52.9</td>\n",
              "      <td>46.5</td>\n",
              "      <td>37.4</td>\n",
              "      <td>36.9</td>\n",
              "      <td>65.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>E8</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2016</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>ACC</td>\n",
              "      <td>37</td>\n",
              "      <td>29</td>\n",
              "      <td>119.9</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.9600</td>\n",
              "      <td>54.8</td>\n",
              "      <td>48.4</td>\n",
              "      <td>15.1</td>\n",
              "      <td>18.8</td>\n",
              "      <td>29.9</td>\n",
              "      <td>25.2</td>\n",
              "      <td>32.1</td>\n",
              "      <td>33.4</td>\n",
              "      <td>52.6</td>\n",
              "      <td>46.3</td>\n",
              "      <td>40.3</td>\n",
              "      <td>34.7</td>\n",
              "      <td>61.9</td>\n",
              "      <td>8.6</td>\n",
              "      <td>E8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kansas</td>\n",
              "      <td>B12</td>\n",
              "      <td>37</td>\n",
              "      <td>32</td>\n",
              "      <td>120.9</td>\n",
              "      <td>90.4</td>\n",
              "      <td>0.9662</td>\n",
              "      <td>55.7</td>\n",
              "      <td>45.1</td>\n",
              "      <td>17.8</td>\n",
              "      <td>18.5</td>\n",
              "      <td>32.2</td>\n",
              "      <td>27.9</td>\n",
              "      <td>38.6</td>\n",
              "      <td>37.3</td>\n",
              "      <td>52.7</td>\n",
              "      <td>43.4</td>\n",
              "      <td>41.3</td>\n",
              "      <td>32.5</td>\n",
              "      <td>70.1</td>\n",
              "      <td>11.6</td>\n",
              "      <td>E8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Oregon</td>\n",
              "      <td>P12</td>\n",
              "      <td>37</td>\n",
              "      <td>30</td>\n",
              "      <td>118.4</td>\n",
              "      <td>96.2</td>\n",
              "      <td>0.9163</td>\n",
              "      <td>52.3</td>\n",
              "      <td>48.9</td>\n",
              "      <td>16.1</td>\n",
              "      <td>20.2</td>\n",
              "      <td>34.1</td>\n",
              "      <td>30.5</td>\n",
              "      <td>40.3</td>\n",
              "      <td>32.0</td>\n",
              "      <td>52.6</td>\n",
              "      <td>46.1</td>\n",
              "      <td>34.4</td>\n",
              "      <td>36.2</td>\n",
              "      <td>69.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>E8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Syracuse</td>\n",
              "      <td>ACC</td>\n",
              "      <td>37</td>\n",
              "      <td>23</td>\n",
              "      <td>111.9</td>\n",
              "      <td>93.6</td>\n",
              "      <td>0.8857</td>\n",
              "      <td>50.0</td>\n",
              "      <td>47.3</td>\n",
              "      <td>18.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>33.5</td>\n",
              "      <td>35.3</td>\n",
              "      <td>35.4</td>\n",
              "      <td>28.0</td>\n",
              "      <td>47.2</td>\n",
              "      <td>48.1</td>\n",
              "      <td>36.0</td>\n",
              "      <td>30.7</td>\n",
              "      <td>65.5</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>F4</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2016</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         TEAM CONF   G   W  ADJOE  ...   WAB  POSTSEASON  SEED  YEAR  windex\n",
              "2  Notre Dame  ACC  36  24  118.3  ...   2.3          E8   6.0  2016   False\n",
              "3    Virginia  ACC  37  29  119.9  ...   8.6          E8   1.0  2016    True\n",
              "4      Kansas  B12  37  32  120.9  ...  11.6          E8   1.0  2016    True\n",
              "5      Oregon  P12  37  30  118.4  ...   6.7          E8   1.0  2016   False\n",
              "6    Syracuse  ACC  37  23  111.9  ...  -0.3          F4  10.0  2016   False\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hoc2pPc7t6TG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "eeb47f2c-b652-411c-a8d1-717643320d8c"
      },
      "source": [
        "df1['POSTSEASON'].value_counts()\n",
        "# 32 teams made it into the Sweet Sixteen, 16 into the Elite Eight, and 8 made it into the Final Four over 5 seasons."
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "S16    32\n",
              "E8     16\n",
              "F4      8\n",
              "Name: POSTSEASON, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjpKAztyt-1N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c35d14a-13c8-477e-cff2-be069b928f99"
      },
      "source": [
        "# plot some columns to underestand data better:\n",
        "\n",
        "!conda install -c anaconda seaborn -y"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: conda: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wu_JUg1uCK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "05da949a-2ab7-4606-8399-585020fd49c6"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "bins = np.linspace(df1.BARTHAG.min(), df1.BARTHAG.max(), 10)\n",
        "g = sns.FacetGrid(df1, col=\"windex\", hue=\"POSTSEASON\", palette=\"Set1\", col_wrap=6)\n",
        "g.map(plt.hist, 'BARTHAG', bins=bins, ec=\"k\")\n",
        "\n",
        "g.axes[-1].legend()\n",
        "plt.show()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAADQCAYAAABr00SDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAV5klEQVR4nO3df5RVZb3H8fdn+DXIiBJgwowDlD8CFCed4mqpc81ryNUMtYveamlXszSt9Jo3V63imq6L6bqWmRVyjX7o7YdlP9SrcVUMU1kBQqkEkpqMgwkkeEkRkO/942zsOA7MmZl9Zs485/Naay/22efZ+/k+MF++Z++zZz+KCMzMzFJR09cBmJmZ5cmFzczMkuLCZmZmSXFhMzOzpLiwmZlZUlzYzMwsKS5svUjSnZL27kL78ZIeLWdMu+h3gaSVkpZly2mdtG3uzfjM2usPuSXptiyfVkvaVJRfR/ZmHNVgYF8HUE0iYnpfx9AFH4yIxX0dhFkp+kNuRcQMAEktwCURcWLx+5IGRsT2vogtNT5jy4mkz0j6ZLZ+raR7s/VjJd2crT8taVT2aXGFpBslPSbpV5KGZm0Ol7Rc0nLgE0XHHyDpakm/lfQ7SR/Ltl8k6aZs/RBJj0raowzj+4akxVm8/97B+wMkzcv6/72ki7Ltb5V0l6QlkhZKelvesVnaUs4tSWdJ+kU2pnsktUi6vej96yWdVRT//Vku3S1pTJ6xpMSFLT8LgaOy9WagTtKgbNuvO2h/APD1iJgMbAROzbZ/G7gwIg5t1/5sYFNEvAN4B/BRSROArwL7S5qR7fuxiHipeEdJBxVd9mi/7Oryzc1FbUYCn4uIZmAKcIykKe3aNwH1EXFwRBySxQIwJxvP4cAlwA276M9sV1LLrfYOA06LiGN21SAb79eydocDNwFXlnj8quNLkflZAhwuaTjwCrCUQhIeBXyyg/ZPRcSyon3HZ4mwd0TsTNbvASdk68cDU4q+79oLOCAinso+0f0O+FZE/KZ9RxGxkkLh6YrXXYqU9HFJ51L4mRkDTMr63OlJ4C2SvgbcAfxKUh1wJPBjSTvbDeliHGap5VZ78yPiL520OQg4GJif5dIAYG0P+02WC1tOImKbpKeAs4AHKSTD3wP7Ays62OWVovVXgaGddCEKnzbv7uC9A4DNwNgOd5QOAn64i+O2RMTG3XZc+PR6CfCOiHhB0jygtrhNtv1Q4L3Ax4F/Aj4NbIyInia+VbGUcyvz16L17bz+StrOPBPwWEQcUcLxqp4vReZrIYUC8Ots/ePAI1Hik6azJNgo6d3Zpg8WvX03cF52SQJJB0oaJmkv4DrgaGCkOriDMSJWRkTTLpZSEm84heTbJOnN/O2T7mskjQJqIuInwOeBwyLiReApSR/I2igrfmZdlWputfcnYJKkIdlZ5nuy7SuB0ZKOyGIcJGlyN45fFVzY8rWQwmW6hyLiz8CWbFtXfAT4uqRlFD6l7TQXeBxYqsJtyt+icMZ9LYXvE1ZR+K5gtqR9ejaM14uI5cAjwB+AW4A3XJIB6oEFWdzfBy7Ltn8QODv7wv4x4OQ8Y7OqkWRutRcRa4AfAY9mfz6Sbd8KnAZcleXSMgqX+a0D8rQ1ZmaWEp+xmZlZUlzYzMwsKS5sZmaWFBc2MzNLSlkK27Rp0wLw4sXL65ducT558dLhsktlKWzr168vx2HNqpLzyaxrfCnSzMyS4sJmZmZJKamwZdM3PJZN2/Dfkmo738vMzKz3dfoQZEn1FJ6gPSkiXpb0I+B0YF6ZYzMzsxJt27aN1tZWtmzZ0teh5Kq2tpaGhgYGDRpU8j6lPt1/IDBU0jZgD6CtG/GZmVmZtLa2sueeezJ+/HiKponq1yKCDRs20NrayoQJE0rer9NLkRHxLHAN8AyF+X82RcSvuh2pmZnlbsuWLYwcOTKZogYgiZEjR3b5LLTTwiZpBIUnsk+gMCfRMEkf6qDduZIWS1q8bt26LgVhfa++sR5JuS31jfV9PaR+zflk3ZFSUdupO2Mq5VLkcRRmpF2XdfJTCtMlfL+4UUTMAeYANDc37/aX56zytK1p46Tbpud2vF/OuDO3Y1Uj55NZ95VyV+QzwN9J2kOF0vkeOp611szMKsS4MWNyvQozbsyYTvscMGAATU1Nry2zZ88G4J577uGwww6jqamJd7/73axevbqsY+/0jC0iFkm6FVhKYdryR8g+SZqZWWV65rnnaB3bkNvxGtpaO20zdOhQli1b9obt5513Hj//+c+ZOHEiN9xwA1dccQXz5s3LLbb2SrorMiK+CHyxbFGYmVmyJPHiiy8CsGnTJsaOHVvW/kq93d/MzGy3Xn75ZZqaml57fdlllzFz5kzmzp3L9OnTGTp0KMOHD+fhhx8uaxwubGZmlotdXYq89tprufPOO5k6dSpXX301F198MXPnzi1bHH5WpJmZlc26detYvnw5U6dOBWDmzJk8+OCDZe3Thc3MzMpmxIgRbNq0iVWrVgEwf/58Jk6cWNY+fSnSzCxBjfvuW9KdjF05Xmfaf8c2bdo0Zs+ezY033sipp55KTU0NI0aM4Kabbsotro64sJmZJehPa9f2ep+vvvpqh9tnzJjBjBkzei0OX4o0M7OkuLCZmVlSXNjMzCwpLmxmZpYUFzYzM0uKC5uZmSXFhc3MLEFjGxpznbZmbENjp322n7bm6aeffu29Z555hrq6Oq655poyjrrAv8dmZpagtc+uYeoX7srteIsun9Zpm109KxLg4osv5oQTTsgtnt1xYTMzs7L62c9+xoQJExg2bFiv9OdLkWZmloudj9Rqamp67Ukjmzdv5qqrruKLX+y9KT19xmZmZrno6FLkrFmzuOiii6irq+u1OFzYzMysbBYtWsStt97KpZdeysaNG6mpqaG2tpYLLrigbH26sJmZWdksXLjwtfVZs2ZRV1dX1qIGLmxmZkkaU79fSXcyduV4/YULm5lZgtpan+n1Pjdv3rzb92fNmtUrcfiuSDMzS4oLm5mZJcWFzczMkuLCZmZmSXFhMzOzpLiwmZlZUkoqbJL2lnSrpD9IWiHpiHIHZmZm3VffWJ/rtDX1jfUl9XvllVcyefJkpkyZQlNTE4sWLeL6669n//33RxLr169/XfsFCxbQ1NTE5MmTOeaYY3IZe6m/x/ZV4K6IOE3SYGCPXHo3M7OyaFvTxkm3Tc/teL+ccWenbR566CFuv/12li5dypAhQ1i/fj1bt25l8ODBnHjiibS0tLyu/caNGzn//PO56667aGxs5Pnnn88l1k4Lm6S9gKOBswAiYiuwNZfezcwsGWvXrmXUqFEMGTIEgFGjRgEwduzYDtvfcsstnHLKKTQ2FiYx3WeffXKJo5RLkROAdcC3JT0iaa6kN0yqI+lcSYslLV63bl0uwZlVK+eT9UfHH388a9as4cADD+T888/n/vvv3237VatW8cILL9DS0sLhhx/Od7/73VziKKWwDQQOA74REW8H/gp8tn2jiJgTEc0R0Tx69OhcgjOrVs4n64/q6upYsmQJc+bMYfTo0cycOZN58+btsv327dtZsmQJd9xxB3fffTdf+tKXWLVqVY/jKOU7tlagNSIWZa9vpYPCZmZmNmDAAFpaWmhpaeGQQw7hO9/5DmeddVaHbRsaGhg5ciTDhg1j2LBhHH300SxfvpwDDzywRzF0esYWEc8BayQdlG16D/B4j3o1M7PkrFy5kieeeOK118uWLWPcuHG7bH/yySfzwAMPsH37dl566SUWLVrExIkTexxHqXdFXgjcnN0R+STwkR73bGZmZTN2v7El3cnYleN1ZvPmzVx44YVs3LiRgQMHsv/++zNnzhyuu+46vvzlL/Pcc88xZcoUpk+fzty5c5k4cSLTpk1jypQp1NTUcM4553DwwQf3OFZFRI8P0l5zc3MsXrw49+Na+UjK/dbgcvxs9XPqzk7OJyvFihUrcjnbqUS7GNsu88lPHjEzs6S4sJmZWVJc2MzMEpHi5f/ujMmFzcwsAbW1tWzYsCGp4hYRbNiwgdra2i7tV+pdkWZmVsEaGhpobW0ltSfV1NbW0tDQ0KV9XNjMzBIwaNAgJkyY0NdhVARfijQzs6S4sJmZWVJc2MzMLCkubGZmlhQXNjMzS4oLm5mZJcWFzcqiZlANknJb6hvr+3pIZtZP+PfYrCx2bNuR+2wBZmal8BmbmZklxYXNzMyS4sJmZmZJcWEzM7OkuLCZmVlSXNjMzCwpLmxmZpYUFzYzM0uKC5uZmSXFhc3MzJLiwmZmZklxYTMzs6SUXNgkDZD0iKTbyxmQmZlZT3TljO1TwIpyBWJmZpaHkgqbpAbgH4G55Q3HzMysZ0o9Y/sKcCmwo4yxmJmZ9VinhU3SicDzEbGkk3bnSlosafG6detyC9CsGjmfzLqvlDO2dwHvk/Q08APgWEnfb98oIuZERHNENI8ePTrnMM2qi/PJrPs6LWwRcVlENETEeOB04N6I+FDZIzMzM+sG/x6bmZklZWBXGkfEAmBBWSIxMzPLgc/YzMwsKS5sZmaWFBc2MzNLigubmZklxYXNzMyS4sJmZmZJcWEzM7OkuLCZmVlSXNjMzCwpLmxmZpYUFzYzM0uKC5uZmSXFha2fqm+sR1Jui5nlJ+/8rG+szzW+wbWDco1v4OABuR5v3JgxPRpfl57ub5WjbU0bJ902Pbfj/XLGnbkdy6zaVXp+bntle+7xtY5tyO14DW2tPdrfZ2xmZpYUFzYzM0uKC5uZmSXFhc3MzJLiwmZmZklxYTMzs6S4sJmZWVJc2MzMLCkubGZmlhQXNjMzS4oLm5mZJcWFzczMkuLCZmZmSem0sEnaT9J9kh6X9JikT/VGYGZmZt1RyrQ124F/jYilkvYElkiaHxGPlzk2MzOzLuv0jC0i1kbE0mz9/4AVQL6z3pmZmeWkSxONShoPvB1Y1MF75wLnAjQ2NuYQWtfUN9bTtqYtt+PVDK5hx9YduR1v0JCBbN2yLbfjVaM8Z/oeWjOAl3e8mtvxGvfdlz+tXZvb8fo6n6zyVPJM9zWDano8OWj74/VEyYVNUh3wE+DTEfFi+/cjYg4wB6C5uTl6FFU3lGPG2kqeAbca5T1DbyXN+NteX+eTVZ6pX7grt2MtunxabscC2LFtR0X9f1lSWZQ0iEJRuzkiftqjHs3MzMqolLsiBfwXsCIi/rP8IZmZmXVfKWds7wI+DBwraVm25HfOaWZmlqNOv2OLiAeAyv3W0szMrIifPGJmZklxYTMzs6S4sJmZWVJc2MzMLCkubGZmlhQXNjMzS4oLm5mZJcWFzczMkuLCZmZmSXFhMzOzpLiwmZlZUlzYzMwsKV2aQTtPg2sHse2V7X3Vfa+rGVRT0TPgVrpKm6HX0lLfWE/bmra+DsNy0meFbdsr2ytqxtVyq7QZZvsb//1ZObWtafPPV0L8sdXMzJLiwmZmZklxYTMzs6S4sJmZWVJc2MzMLCkubGZmlhQXNjMzS4oLm5mZJcWFzczMkuLCZmZmSXFhMzOzpLiwmZlZUlzYzMwsKSUVNknTJK2UtFrSZ8sdlJmZWXd1WtgkDQC+DpwATALOkDSp3IGZmZl1RylnbO8EVkfEkxGxFfgBcHJ5wzIzM+seRcTuG0inAdMi4pzs9YeBqRFxQbt25wLnZi8PAlbmH26PjALW93UQvcxjrizrI2JaKQ2dTxWpGscMlTvuXeZTbjNoR8QcYE5ex8ubpMUR0dzXcfQmj7n/cj5VnmocM/TPcZdyKfJZYL+i1w3ZNjMzs4pTSmH7LXCApAmSBgOnA78ob1hmZmbd0+mlyIjYLukC4G5gAHBTRDxW9sjyV7GXdcrIY7Zyqca/52ocM/TDcXd684iZmVl/4iePmJlZUlzYzMwsKf2+sHX2uC9JjZLuk/SIpN9Jmp5tHy/pZUnLsuWbvR9995Qw5nGS7snGu0BSQ9F7Z0p6IlvO7N3Ie6aH43616N/aNz/thnOqOnIq6XyKiH67ULiZ5Y/AW4DBwHJgUrs2c4DzsvVJwNPZ+njg0b4eQ5nG/GPgzGz9WOB72fqbgCezP0dk6yP6ekzlHnf2enNfj6E/LM6p6sip1POpv5+xlfK4rwCGZ+t7AW29GF85lDLmScC92fp9Re+/F5gfEX+JiBeA+UBJT8KoAD0Zt5XOOVUdOZV0PvX3wlYPrCl63ZptKzYL+JCkVuBO4MKi9yZkl1Pul3RUWSPNTyljXg6ckq3PAPaUNLLEfStVT8YNUCtpsaSHJb2/vKH2a86p6sippPOpvxe2UpwBzIuIBmA68D1JNcBaoDEi3g5cDNwiafhujtOfXAIcI+kR4BgKT4p5tW9D6hW7G/e4KDwW6J+Br0h6ax/FmALnVHXkVL/Np9yeFdlHSnnc19lklwYi4iFJtcCoiHgeeCXbvkTSH4EDgcVlj7pnOh1zRLSRfdKSVAecGhEbJT0LtLTbd0E5g81Rt8edvfds9ueTkhYAb6fwHYO9nnOqOnIq7Xzq6y/5erJQKMxPAhP42xegk9u1+R/grGx9IoXvAwSMBgZk299C4R/1TX09ppzGPAqoydavBC7P1t8EPEXhS+4R2XrFjzmHcY8AhhS1eYJ2X5R76dLfs3Oqn+dU6vnU5wHk8A80HVhF4dPC57JtlwPvy9YnAb/J/uGWAcdn208FHsu2LQVO6uux5Djm07IftlXA3J0/hNl7/wKszpaP9PVYemPcwJHA77Ofgd8DZ/f1WCp5cU5VR06lnE9+pJaZmSWlGm4eMTOzKuLCZmZmSXFhMzOzpLiwmZlZUlzYzMwsKS5sFaDoSdnLJS2VdGS79z8taYukvYq2tUjalO33B0nXSDqk6Inbf5H0VLb+v9mT1x9td9xZki4pej1Q0jpJs9u1q5P0DUl/zOJbIumj5fr7MOsJ55O5sFWGlyOiKSIOBS4D/qPd+2cAv+Vvz23baWFENFH4rf8TgeHZcZqAXwCfyV4fV2Ic/0Dhd1Y+IElF2+cCLwAHRMRhFJ468aYujM+sNzmfqpwLW+UZTuGHHoDsGWx1wOcpJOQbRMTLFH4ptqcPXz0D+CrwDHBEUf/vBD4fETuy/tZFxFU97MusNzifqlB/f1ZkKoZKWgbUAmMozH200+kUppRYCBwk6c0R8efinSWNAA4Aft1JP2/N+tlpX+Ca7Bi1wHHAx4C9KSTlg8BkYPnOJDTrB5xPVc5nbJVh56WTt1G4LPHdoksXZwA/yBLhJ8AHivY7StJyCs/kuzsinuuknz/uvLSSXV4pnuH4ROC+7NPqT4D3SxrQ/gCSPpd9z9Df5+CydDmfqpwLW4WJiIcoPFh0tKRDKHxynC/paQqfNosvnyzMvkeYDJwtqakHXZ8BHJf1swQYSeGT7uPAodm0JETElVkSpzIdiSXM+VSdXNgqjKS3UZi2fQOF5JgVEeOzZSwwVtK44n0i4ilgNvBv3exzOHAUhbm0xkfEeOATwBkRsZrCtCNX7PzEmV1m0a6OZ1YpnE/VyYWtMgzdeVsx8EPgzIh4lcInytvatb0t297eN4GjJY3vRv8zgHsj4pWibT8HTpI0BDiHwifO1ZIWA/OBS7vRj1lvcD5VOT/d38zMkuIzNjMzS4oLm5mZJcWFzczMkuLCZmZmSXFhMzOzpLiwmZlZUlzYzMwsKf8P6pA578CH4cQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1296x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP3PB69euEhs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "d74d214a-b78b-4686-c196-d6f22f515fc3"
      },
      "source": [
        "bins = np.linspace(df1.ADJOE.min(), df1.ADJOE.max(), 10)\n",
        "g = sns.FacetGrid(df1, col=\"windex\", hue=\"POSTSEASON\", palette=\"Set1\", col_wrap=2)\n",
        "g.map(plt.hist, 'ADJOE', bins=bins, ec=\"k\")\n",
        "\n",
        "g.axes[-1].legend()\n",
        "plt.show()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih0EDeAkuG7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "676784c3-d7fa-49d7-9d53-b76d6dd590e3"
      },
      "source": [
        "# Pre-processing: Feature selection/extraction\n",
        "# look at how Adjusted Defense Efficiency plots\n",
        "bins = np.linspace(df1.ADJDE.min(), df1.ADJDE.max(), 10)\n",
        "g = sns.FacetGrid(df1, col=\"windex\", hue=\"POSTSEASON\", palette=\"Set1\", col_wrap=2)\n",
        "g.map(plt.hist, 'ADJDE', bins=bins, ec=\"k\")\n",
        "g.axes[-1].legend()\n",
        "plt.show()\n",
        "\n",
        "# see that this data point doesn't impact the ability of a team to get into the Final Four."
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-1OmetpuKeg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a0c5d30e-d3ef-4f43-d5c1-4bc2d42c4103"
      },
      "source": [
        "# Convert Categorical features to numerical values\n",
        "# look at the postseason:\n",
        "\n",
        "df1.groupby(['windex'])['POSTSEASON'].value_counts(normalize=True)\n",
        "\n",
        "# 13% of teams with 6 or less wins above bubble make it into the final four while 17% of teams with 7 or more do."
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "windex  POSTSEASON\n",
              "False   S16           0.605263\n",
              "        E8            0.263158\n",
              "        F4            0.131579\n",
              "True    S16           0.500000\n",
              "        E8            0.333333\n",
              "        F4            0.166667\n",
              "Name: POSTSEASON, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MyILnt_uTvB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "4d5cc0fe-05fc-44a2-c324-31bb5ce5b5ca"
      },
      "source": [
        "# convert wins above bubble (winindex) under 7 to 0 and over 7 to 1:\n",
        "\n",
        "df1['windex'].replace(to_replace=['False','True'], value=[0,1],inplace=True)\n",
        "df1.head()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:6746: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._update_inplace(new_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEAM</th>\n",
              "      <th>CONF</th>\n",
              "      <th>G</th>\n",
              "      <th>W</th>\n",
              "      <th>ADJOE</th>\n",
              "      <th>ADJDE</th>\n",
              "      <th>BARTHAG</th>\n",
              "      <th>EFG_O</th>\n",
              "      <th>EFG_D</th>\n",
              "      <th>TOR</th>\n",
              "      <th>TORD</th>\n",
              "      <th>ORB</th>\n",
              "      <th>DRB</th>\n",
              "      <th>FTR</th>\n",
              "      <th>FTRD</th>\n",
              "      <th>2P_O</th>\n",
              "      <th>2P_D</th>\n",
              "      <th>3P_O</th>\n",
              "      <th>3P_D</th>\n",
              "      <th>ADJ_T</th>\n",
              "      <th>WAB</th>\n",
              "      <th>POSTSEASON</th>\n",
              "      <th>SEED</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>windex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Notre Dame</td>\n",
              "      <td>ACC</td>\n",
              "      <td>36</td>\n",
              "      <td>24</td>\n",
              "      <td>118.3</td>\n",
              "      <td>103.3</td>\n",
              "      <td>0.8269</td>\n",
              "      <td>54.0</td>\n",
              "      <td>49.5</td>\n",
              "      <td>15.3</td>\n",
              "      <td>14.8</td>\n",
              "      <td>32.7</td>\n",
              "      <td>32.1</td>\n",
              "      <td>32.9</td>\n",
              "      <td>26.0</td>\n",
              "      <td>52.9</td>\n",
              "      <td>46.5</td>\n",
              "      <td>37.4</td>\n",
              "      <td>36.9</td>\n",
              "      <td>65.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>E8</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>ACC</td>\n",
              "      <td>37</td>\n",
              "      <td>29</td>\n",
              "      <td>119.9</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.9600</td>\n",
              "      <td>54.8</td>\n",
              "      <td>48.4</td>\n",
              "      <td>15.1</td>\n",
              "      <td>18.8</td>\n",
              "      <td>29.9</td>\n",
              "      <td>25.2</td>\n",
              "      <td>32.1</td>\n",
              "      <td>33.4</td>\n",
              "      <td>52.6</td>\n",
              "      <td>46.3</td>\n",
              "      <td>40.3</td>\n",
              "      <td>34.7</td>\n",
              "      <td>61.9</td>\n",
              "      <td>8.6</td>\n",
              "      <td>E8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kansas</td>\n",
              "      <td>B12</td>\n",
              "      <td>37</td>\n",
              "      <td>32</td>\n",
              "      <td>120.9</td>\n",
              "      <td>90.4</td>\n",
              "      <td>0.9662</td>\n",
              "      <td>55.7</td>\n",
              "      <td>45.1</td>\n",
              "      <td>17.8</td>\n",
              "      <td>18.5</td>\n",
              "      <td>32.2</td>\n",
              "      <td>27.9</td>\n",
              "      <td>38.6</td>\n",
              "      <td>37.3</td>\n",
              "      <td>52.7</td>\n",
              "      <td>43.4</td>\n",
              "      <td>41.3</td>\n",
              "      <td>32.5</td>\n",
              "      <td>70.1</td>\n",
              "      <td>11.6</td>\n",
              "      <td>E8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Oregon</td>\n",
              "      <td>P12</td>\n",
              "      <td>37</td>\n",
              "      <td>30</td>\n",
              "      <td>118.4</td>\n",
              "      <td>96.2</td>\n",
              "      <td>0.9163</td>\n",
              "      <td>52.3</td>\n",
              "      <td>48.9</td>\n",
              "      <td>16.1</td>\n",
              "      <td>20.2</td>\n",
              "      <td>34.1</td>\n",
              "      <td>30.5</td>\n",
              "      <td>40.3</td>\n",
              "      <td>32.0</td>\n",
              "      <td>52.6</td>\n",
              "      <td>46.1</td>\n",
              "      <td>34.4</td>\n",
              "      <td>36.2</td>\n",
              "      <td>69.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>E8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Syracuse</td>\n",
              "      <td>ACC</td>\n",
              "      <td>37</td>\n",
              "      <td>23</td>\n",
              "      <td>111.9</td>\n",
              "      <td>93.6</td>\n",
              "      <td>0.8857</td>\n",
              "      <td>50.0</td>\n",
              "      <td>47.3</td>\n",
              "      <td>18.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>33.5</td>\n",
              "      <td>35.3</td>\n",
              "      <td>35.4</td>\n",
              "      <td>28.0</td>\n",
              "      <td>47.2</td>\n",
              "      <td>48.1</td>\n",
              "      <td>36.0</td>\n",
              "      <td>30.7</td>\n",
              "      <td>65.5</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>F4</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         TEAM CONF   G   W  ADJOE  ...   WAB  POSTSEASON  SEED  YEAR  windex\n",
              "2  Notre Dame  ACC  36  24  118.3  ...   2.3          E8   6.0  2016       0\n",
              "3    Virginia  ACC  37  29  119.9  ...   8.6          E8   1.0  2016       1\n",
              "4      Kansas  B12  37  32  120.9  ...  11.6          E8   1.0  2016       1\n",
              "5      Oregon  P12  37  30  118.4  ...   6.7          E8   1.0  2016       0\n",
              "6    Syracuse  ACC  37  23  111.9  ...  -0.3          F4  10.0  2016       0\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHjgjcJkuWLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "79b56e06-a92a-4161-96a7-857ad44db0dd"
      },
      "source": [
        "# Feature selection\n",
        "# define feature sets, X:\n",
        "\n",
        "X = df1[['G', 'W', 'ADJOE', 'ADJDE', 'BARTHAG', 'EFG_O', 'EFG_D',\n",
        "       'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P_O', '2P_D', '3P_O',\n",
        "       '3P_D', 'ADJ_T', 'WAB', 'SEED', 'windex']]\n",
        "X[0:5]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>G</th>\n",
              "      <th>W</th>\n",
              "      <th>ADJOE</th>\n",
              "      <th>ADJDE</th>\n",
              "      <th>BARTHAG</th>\n",
              "      <th>EFG_O</th>\n",
              "      <th>EFG_D</th>\n",
              "      <th>TOR</th>\n",
              "      <th>TORD</th>\n",
              "      <th>ORB</th>\n",
              "      <th>DRB</th>\n",
              "      <th>FTR</th>\n",
              "      <th>FTRD</th>\n",
              "      <th>2P_O</th>\n",
              "      <th>2P_D</th>\n",
              "      <th>3P_O</th>\n",
              "      <th>3P_D</th>\n",
              "      <th>ADJ_T</th>\n",
              "      <th>WAB</th>\n",
              "      <th>SEED</th>\n",
              "      <th>windex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36</td>\n",
              "      <td>24</td>\n",
              "      <td>118.3</td>\n",
              "      <td>103.3</td>\n",
              "      <td>0.8269</td>\n",
              "      <td>54.0</td>\n",
              "      <td>49.5</td>\n",
              "      <td>15.3</td>\n",
              "      <td>14.8</td>\n",
              "      <td>32.7</td>\n",
              "      <td>32.1</td>\n",
              "      <td>32.9</td>\n",
              "      <td>26.0</td>\n",
              "      <td>52.9</td>\n",
              "      <td>46.5</td>\n",
              "      <td>37.4</td>\n",
              "      <td>36.9</td>\n",
              "      <td>65.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37</td>\n",
              "      <td>29</td>\n",
              "      <td>119.9</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.9600</td>\n",
              "      <td>54.8</td>\n",
              "      <td>48.4</td>\n",
              "      <td>15.1</td>\n",
              "      <td>18.8</td>\n",
              "      <td>29.9</td>\n",
              "      <td>25.2</td>\n",
              "      <td>32.1</td>\n",
              "      <td>33.4</td>\n",
              "      <td>52.6</td>\n",
              "      <td>46.3</td>\n",
              "      <td>40.3</td>\n",
              "      <td>34.7</td>\n",
              "      <td>61.9</td>\n",
              "      <td>8.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37</td>\n",
              "      <td>32</td>\n",
              "      <td>120.9</td>\n",
              "      <td>90.4</td>\n",
              "      <td>0.9662</td>\n",
              "      <td>55.7</td>\n",
              "      <td>45.1</td>\n",
              "      <td>17.8</td>\n",
              "      <td>18.5</td>\n",
              "      <td>32.2</td>\n",
              "      <td>27.9</td>\n",
              "      <td>38.6</td>\n",
              "      <td>37.3</td>\n",
              "      <td>52.7</td>\n",
              "      <td>43.4</td>\n",
              "      <td>41.3</td>\n",
              "      <td>32.5</td>\n",
              "      <td>70.1</td>\n",
              "      <td>11.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>37</td>\n",
              "      <td>30</td>\n",
              "      <td>118.4</td>\n",
              "      <td>96.2</td>\n",
              "      <td>0.9163</td>\n",
              "      <td>52.3</td>\n",
              "      <td>48.9</td>\n",
              "      <td>16.1</td>\n",
              "      <td>20.2</td>\n",
              "      <td>34.1</td>\n",
              "      <td>30.5</td>\n",
              "      <td>40.3</td>\n",
              "      <td>32.0</td>\n",
              "      <td>52.6</td>\n",
              "      <td>46.1</td>\n",
              "      <td>34.4</td>\n",
              "      <td>36.2</td>\n",
              "      <td>69.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>37</td>\n",
              "      <td>23</td>\n",
              "      <td>111.9</td>\n",
              "      <td>93.6</td>\n",
              "      <td>0.8857</td>\n",
              "      <td>50.0</td>\n",
              "      <td>47.3</td>\n",
              "      <td>18.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>33.5</td>\n",
              "      <td>35.3</td>\n",
              "      <td>35.4</td>\n",
              "      <td>28.0</td>\n",
              "      <td>47.2</td>\n",
              "      <td>48.1</td>\n",
              "      <td>36.0</td>\n",
              "      <td>30.7</td>\n",
              "      <td>65.5</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    G   W  ADJOE  ADJDE  BARTHAG  EFG_O  ...  3P_O  3P_D  ADJ_T   WAB  SEED  windex\n",
              "2  36  24  118.3  103.3   0.8269   54.0  ...  37.4  36.9   65.5   2.3   6.0       0\n",
              "3  37  29  119.9   91.0   0.9600   54.8  ...  40.3  34.7   61.9   8.6   1.0       1\n",
              "4  37  32  120.9   90.4   0.9662   55.7  ...  41.3  32.5   70.1  11.6   1.0       1\n",
              "5  37  30  118.4   96.2   0.9163   52.3  ...  34.4  36.2   69.0   6.7   1.0       0\n",
              "6  37  23  111.9   93.6   0.8857   50.0  ...  36.0  30.7   65.5  -0.3  10.0       0\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKp36PYxuaC0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb7476bf-a702-4698-b9e0-ccdfb47994a4"
      },
      "source": [
        "# Labels? Round where the given team was eliminated or where their season ended \n",
        "# (R68 = First Four, R64 = Round of 64, R32 = Round of 32, S16 = Sweet Sixteen, E8 = Elite Eight, F4 = Final Four, 2ND = Runner-up, Champion = Winner of the NCAA March Madness Tournament for that given year)|\n",
        "\n",
        "y = df1['POSTSEASON'].values\n",
        "y[0:5]"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['E8', 'E8', 'E8', 'E8', 'F4'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2yvlCOFudMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "07394ce0-2460-4eee-f20a-70524d62ba89"
      },
      "source": [
        "# Normalize Data\n",
        "# Data Standardization give data zero mean and unit variance (technically should be done after train test split )\n",
        "\n",
        "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
        "X[0:5]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.43331874, -1.26140173,  0.28034482,  2.74329908, -2.45717765,\n",
              "         0.10027963,  0.94171924, -1.16188145, -1.71391372,  0.12750511,\n",
              "         1.33368704, -0.4942211 , -0.87998988,  0.02784185,  0.00307239,\n",
              "         0.22576157,  1.59744386, -1.12106011, -1.0448016 ,  0.49716104,\n",
              "        -0.6882472 ],\n",
              "       [ 0.40343468,  0.35874728,  0.64758014, -0.90102957,  1.127076  ,\n",
              "         0.39390887,  0.38123706, -1.29466791, -0.03522254, -0.62979797,\n",
              "        -1.31585883, -0.68542235,  0.55458056, -0.07167795, -0.0829545 ,\n",
              "         1.32677295,  0.65081046, -2.369021  ,  0.98050611, -1.14054592,\n",
              "         1.45296631],\n",
              "       [ 0.40343468,  1.33083669,  0.87710222, -1.0788017 ,  1.29403598,\n",
              "         0.72424177, -1.30020946,  0.49794919, -0.16112438, -0.00772758,\n",
              "        -0.27908001,  0.86808783,  1.31063795, -0.03850468, -1.33034432,\n",
              "         1.70643205, -0.29582294,  0.47355659,  1.94493836, -1.14054592,\n",
              "         1.45296631],\n",
              "       [ 0.40343468,  0.68277708,  0.30329703,  0.63966222, -0.04972253,\n",
              "        -0.52368251,  0.63600169, -0.63073565,  0.55231938,  0.50615665,\n",
              "         0.71929959,  1.2743905 ,  0.28317534, -0.07167795, -0.16898138,\n",
              "        -0.91321572,  1.29624232,  0.0922352 ,  0.36969903, -1.14054592,\n",
              "        -0.6882472 ],\n",
              "       [ 0.40343468, -1.58543153, -1.18859646, -0.13068368, -0.87375079,\n",
              "        -1.36786658, -0.17924511,  0.69712887,  0.63625394,  0.34387742,\n",
              "         2.56246194,  0.10328282, -0.49226814, -1.8630343 ,  0.69128747,\n",
              "        -0.30576117, -1.07034117, -1.12106011, -1.88064288,  1.80732661,\n",
              "        -0.6882472 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1AmxeGuuhKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2244efb0-889d-47db-9d20-598e4722eb3f"
      },
      "source": [
        "# Training and Validation\n",
        "# Split the data into Training and Validation data.\n",
        "\n",
        "# split the X into train and test to find the best k\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=4)\n",
        "print ('Train set:', X_train.shape,  y_train.shape)\n",
        "print ('Validation set:', X_val.shape,  y_val.shape)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set: (44, 21) (44,)\n",
            "Validation set: (12, 21) (12,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9Whz8C0ulq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classification\n",
        "# use the training set to build an accurate model. use the validation set to report the accuracy of the model You should use the following algorithm:\n",
        "\n",
        "# K Nearest Neighbor(KNN)\n",
        "# Decision Tree\n",
        "# Support Vector Machine\n",
        "# Logistic Regression\n",
        "# K Nearest Neighbor(KNN)\n",
        "\n",
        "# Build a KNN model using a value of k equals five, find the accuracy on the validation data (X_val and y_val)\n",
        "\n",
        "# can use  accuracy_score\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne3Ot4AXuseA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Determine and print the accuracy for the first 15 values of k the on the validation data:"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyYvYclyuu1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decision Tree\n",
        "# The following lines of code fit a DecisionTreeClassifier:\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Determine the minumum value for the parameter max_depth that improves results"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GyhIqxsu0Dp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Support Vector Machine\n",
        "# Train the support vector machine model and determine the accuracy on the validation data for each kernel. Find the kernel (linear, poly, rbf, sigmoid) that provides the best score on the validation data and train a SVM using it.\n",
        "\n",
        "from sklearn import svm"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6VmwFmGu3Pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic Regression\n",
        "# Train a logistic regression model and determine the accuracy of the validation data (set C=0.01)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn3tBY7Ou8fB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Evaluation using Test set\n",
        "from sklearn.metrics import f1_score\n",
        "# for f1_score please set the average parameter to 'micro'\n",
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXpF-z6pu-Qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def jaccard_index(predictions, true):\n",
        "    if (len(predictions) == len(true)):\n",
        "        intersect = 0;\n",
        "        for x,y in zip(predictions, true):\n",
        "            if (x == y):\n",
        "                intersect += 1\n",
        "        return intersect / (len(predictions) + len(true) - intersect)\n",
        "    else:\n",
        "        return -1"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CT5DkosvAXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b57fc4d4-167c-4c21-9dc8-49ec038b9b5f"
      },
      "source": [
        "# Calculate the F1 score and Jaccard Similarity score for each model from above. Use the Hyperparameter that performed best on the validation data. \n",
        "# For f1_score please set the average parameter to 'micro'.\n",
        "\n",
        "# Load Test set for evaluation\n",
        "test_df = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0120ENv3/Dataset/ML0101EN_EDX_skill_up/basketball_train.csv',error_bad_lines=False)\n",
        "test_df.head()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEAM</th>\n",
              "      <th>CONF</th>\n",
              "      <th>G</th>\n",
              "      <th>W</th>\n",
              "      <th>ADJOE</th>\n",
              "      <th>ADJDE</th>\n",
              "      <th>BARTHAG</th>\n",
              "      <th>EFG_O</th>\n",
              "      <th>EFG_D</th>\n",
              "      <th>TOR</th>\n",
              "      <th>TORD</th>\n",
              "      <th>ORB</th>\n",
              "      <th>DRB</th>\n",
              "      <th>FTR</th>\n",
              "      <th>FTRD</th>\n",
              "      <th>2P_O</th>\n",
              "      <th>2P_D</th>\n",
              "      <th>3P_O</th>\n",
              "      <th>3P_D</th>\n",
              "      <th>ADJ_T</th>\n",
              "      <th>WAB</th>\n",
              "      <th>POSTSEASON</th>\n",
              "      <th>SEED</th>\n",
              "      <th>YEAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>North Carolina</td>\n",
              "      <td>ACC</td>\n",
              "      <td>40</td>\n",
              "      <td>33</td>\n",
              "      <td>123.3</td>\n",
              "      <td>94.9</td>\n",
              "      <td>0.9531</td>\n",
              "      <td>52.6</td>\n",
              "      <td>48.1</td>\n",
              "      <td>15.4</td>\n",
              "      <td>18.2</td>\n",
              "      <td>40.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>32.3</td>\n",
              "      <td>30.4</td>\n",
              "      <td>53.9</td>\n",
              "      <td>44.6</td>\n",
              "      <td>32.7</td>\n",
              "      <td>36.2</td>\n",
              "      <td>71.7</td>\n",
              "      <td>8.6</td>\n",
              "      <td>2ND</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Villanova</td>\n",
              "      <td>BE</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>123.1</td>\n",
              "      <td>90.9</td>\n",
              "      <td>0.9703</td>\n",
              "      <td>56.1</td>\n",
              "      <td>46.7</td>\n",
              "      <td>16.3</td>\n",
              "      <td>20.6</td>\n",
              "      <td>28.2</td>\n",
              "      <td>29.4</td>\n",
              "      <td>34.1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>57.4</td>\n",
              "      <td>44.1</td>\n",
              "      <td>36.2</td>\n",
              "      <td>33.9</td>\n",
              "      <td>66.7</td>\n",
              "      <td>8.9</td>\n",
              "      <td>Champions</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Notre Dame</td>\n",
              "      <td>ACC</td>\n",
              "      <td>36</td>\n",
              "      <td>24</td>\n",
              "      <td>118.3</td>\n",
              "      <td>103.3</td>\n",
              "      <td>0.8269</td>\n",
              "      <td>54.0</td>\n",
              "      <td>49.5</td>\n",
              "      <td>15.3</td>\n",
              "      <td>14.8</td>\n",
              "      <td>32.7</td>\n",
              "      <td>32.1</td>\n",
              "      <td>32.9</td>\n",
              "      <td>26.0</td>\n",
              "      <td>52.9</td>\n",
              "      <td>46.5</td>\n",
              "      <td>37.4</td>\n",
              "      <td>36.9</td>\n",
              "      <td>65.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>E8</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>ACC</td>\n",
              "      <td>37</td>\n",
              "      <td>29</td>\n",
              "      <td>119.9</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.9600</td>\n",
              "      <td>54.8</td>\n",
              "      <td>48.4</td>\n",
              "      <td>15.1</td>\n",
              "      <td>18.8</td>\n",
              "      <td>29.9</td>\n",
              "      <td>25.2</td>\n",
              "      <td>32.1</td>\n",
              "      <td>33.4</td>\n",
              "      <td>52.6</td>\n",
              "      <td>46.3</td>\n",
              "      <td>40.3</td>\n",
              "      <td>34.7</td>\n",
              "      <td>61.9</td>\n",
              "      <td>8.6</td>\n",
              "      <td>E8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kansas</td>\n",
              "      <td>B12</td>\n",
              "      <td>37</td>\n",
              "      <td>32</td>\n",
              "      <td>120.9</td>\n",
              "      <td>90.4</td>\n",
              "      <td>0.9662</td>\n",
              "      <td>55.7</td>\n",
              "      <td>45.1</td>\n",
              "      <td>17.8</td>\n",
              "      <td>18.5</td>\n",
              "      <td>32.2</td>\n",
              "      <td>27.9</td>\n",
              "      <td>38.6</td>\n",
              "      <td>37.3</td>\n",
              "      <td>52.7</td>\n",
              "      <td>43.4</td>\n",
              "      <td>41.3</td>\n",
              "      <td>32.5</td>\n",
              "      <td>70.1</td>\n",
              "      <td>11.6</td>\n",
              "      <td>E8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             TEAM CONF   G   W  ADJOE  ...  ADJ_T   WAB  POSTSEASON  SEED  YEAR\n",
              "0  North Carolina  ACC  40  33  123.3  ...   71.7   8.6         2ND   1.0  2016\n",
              "1       Villanova   BE  40  35  123.1  ...   66.7   8.9   Champions   2.0  2016\n",
              "2      Notre Dame  ACC  36  24  118.3  ...   65.5   2.3          E8   6.0  2016\n",
              "3        Virginia  ACC  37  29  119.9  ...   61.9   8.6          E8   1.0  2016\n",
              "4          Kansas  B12  37  32  120.9  ...   70.1  11.6          E8   1.0  2016\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRSTYhD4vGAR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "b43f17a1-efdd-4f4a-88d6-f37f2eff9b0f"
      },
      "source": [
        "test_df['windex'] = np.where(test_df.WAB > 7, 'True', 'False')\n",
        "test_df1 = test_df[test_df['POSTSEASON'].str.contains('F4|S16|E8', na=False)]\n",
        "test_Feature = test_df1[['G', 'W', 'ADJOE', 'ADJDE', 'BARTHAG', 'EFG_O', 'EFG_D',\n",
        "       'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P_O', '2P_D', '3P_O',\n",
        "       '3P_D', 'ADJ_T', 'WAB', 'SEED', 'windex']]\n",
        "test_Feature['windex'].replace(to_replace=['False','True'], value=[0,1],inplace=True)\n",
        "test_X=test_Feature\n",
        "test_X= preprocessing.StandardScaler().fit(test_X).transform(test_X)\n",
        "test_X[0:5]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:6746: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._update_inplace(new_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.08074446e-01, -1.10135297e+00,  3.37365934e-01,\n",
              "         2.66479976e+00, -2.46831661e+00,  2.13703245e-01,\n",
              "         9.44090550e-01, -1.19216365e+00, -1.64348924e+00,\n",
              "         1.45405982e-02,  1.29523097e+00, -6.23533182e-01,\n",
              "        -9.31788560e-01,  1.42784371e-01,  1.68876201e-01,\n",
              "         2.84500844e-01,  1.62625961e+00, -8.36649260e-01,\n",
              "        -9.98500539e-01,  4.84319174e-01, -6.77003200e-01],\n",
              "       [ 3.63958290e-01,  3.26326807e-01,  7.03145068e-01,\n",
              "        -7.13778644e-01,  1.07370841e+00,  4.82633172e-01,\n",
              "         4.77498943e-01, -1.32975879e+00, -6.86193316e-02,\n",
              "        -7.35448152e-01, -1.35447914e+00, -8.06829025e-01,\n",
              "         3.41737757e-01,  4.96641291e-02,  9.40576311e-02,\n",
              "         1.37214061e+00,  6.93854620e-01, -2.00860931e+00,\n",
              "         9.80549967e-01, -1.19401460e+00,  1.47709789e+00],\n",
              "       [ 3.63958290e-01,  1.18293467e+00,  9.31757027e-01,\n",
              "        -8.78587347e-01,  1.23870131e+00,  7.85179340e-01,\n",
              "        -9.22275877e-01,  5.27775662e-01, -1.86734575e-01,\n",
              "        -1.19385964e-01, -3.17636057e-01,  6.82449703e-01,\n",
              "         1.01292055e+00,  8.07042098e-02, -9.90811637e-01,\n",
              "         1.74718880e+00, -2.38550367e-01,  6.60855252e-01,\n",
              "         1.92295497e+00, -1.19401460e+00,  1.47709789e+00],\n",
              "       [ 3.63958290e-01,  6.11862762e-01,  3.60227129e-01,\n",
              "         7.14563447e-01, -8.92254236e-02, -3.57772849e-01,\n",
              "         6.89586037e-01, -6.41783067e-01,  4.82585136e-01,\n",
              "         3.89534973e-01,  6.80805434e-01,  1.07195337e+00,\n",
              "         1.00800346e-01,  4.96641291e-02,  1.92390609e-02,\n",
              "        -8.40643737e-01,  1.32958529e+00,  3.02756347e-01,\n",
              "         3.83693465e-01, -1.19401460e+00, -6.77003200e-01],\n",
              "       [ 3.63958290e-01, -1.38688893e+00, -1.12575060e+00,\n",
              "         3.92401673e-04, -9.03545224e-01, -1.13094639e+00,\n",
              "         1.09073363e-02,  7.34168378e-01,  5.61328631e-01,\n",
              "         2.28823098e-01,  2.52408203e+00, -5.07336709e-02,\n",
              "        -5.87592258e-01, -1.62650023e+00,  7.67424763e-01,\n",
              "        -2.40566627e-01, -1.00142717e+00, -8.36649260e-01,\n",
              "        -1.81525154e+00,  1.82698619e+00, -6.77003200e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV2k7875vGzF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffcfafe9-ff35-41a7-80f2-63638022ddd7"
      },
      "source": [
        "test_y = test_df1['POSTSEASON'].values\n",
        "test_y[0:5]"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['E8', 'E8', 'E8', 'E8', 'F4'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HEIHsZvvIuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# KNN"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htjnTMv9vLbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decision Tree"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5pySTJ1vNkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enb9jXp4vPOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic Regression"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxhMwxVOvTGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Report\n",
        "# should be able to report the accuracy of the built model using different evaluation metrics:\n",
        "\n",
        "# Algorithm             Accuracy    Jaccard     F1-score\tLogLoss\n",
        "# KNN\t                0.628571\t0.458333\t0.628571\tNA\n",
        "# Decision Tree\t        0.642857\t0.473684\t0.642857\tNA\n",
        "# SVM\t                0.685714\t0.521739\t0.685714\tNA\n",
        "# LogisticRegression\t0.685714\t0.521739\t0.685714\t1.03719\n",
        "\n",
        "# Something to keep in mind when creating models to predict the results of basketball tournaments or sports in general is that is quite hard due to so many factors influencing the game. \n",
        "# Even in sports betting an accuracy of 55% and over is considered good as it indicates profits.\n"
      ],
      "execution_count": 99,
      "outputs": []
    }
  ]
}